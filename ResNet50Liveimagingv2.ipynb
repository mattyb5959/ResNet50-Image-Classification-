{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#scene_dataset = \"C:\\\\Users\\\\MatyuGuerrero\\\\Desktop\\\\Python\\\\Senior Project\\\\scenes\" what data set is doing\n",
    "scene_dataset = 'scenes' #put the filepath for the dataset\n",
    "dataset_path = os.listdir(scene_dataset)\n",
    "scene_types = os.listdir(scene_dataset)\n",
    "print(\"The Scene Types are: \", scene_types) #what kind of scnene images are in this data set\n",
    "print(\"Scenes types found:\", len(scene_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = []\n",
    "\n",
    "for item in scene_types: #This first for loop enters in our folder\n",
    "    all_scenes = os.listdir(scene_dataset + '/' + item) #Gets all the file names\n",
    "    #print(all_scenes)\n",
    "\n",
    "    for scene in all_scenes: #This second list will get all the images of our folder\n",
    "        scenes.append((item, str(scene_dataset + '/' + item) + '/' + scene)) \n",
    "        #print(scenes[:1])\n",
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a data frame\n",
    "\n",
    "scenes_dataframe = pd.DataFrame(data = scenes, columns = ['scene type', 'image']) #scene type shows the class label\n",
    "print(scenes_dataframe.head())\n",
    "#print(scenes_dataframe.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the size of the data set jtsu to see if balanced or unbalanced\n",
    "\n",
    "print(\"Total number of scenes in the dataset:\", len(scenes_dataframe))\n",
    "\n",
    "scene_count = scenes_dataframe['scene type'].value_counts()\n",
    "\n",
    "print(\"scnenes in each category:\")\n",
    "print(scene_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "new_path = 'scenes/'\n",
    "\n",
    "img_size = 224\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in scene_types:\n",
    "    data_path =  new_path + str(i) #uhhhhhhhhh it works?\n",
    "    filenames = [i for i in os.listdir(data_path)]\n",
    "    #print(filenames) #get the names of all the imgs\n",
    "\n",
    "    for f in filenames:\n",
    "        img = cv2.imread(data_path + '/' + f)\n",
    "        \n",
    "        #catches 'bad' imgs \n",
    "        if img is None:\n",
    "            print(f\"Error loading jpg: {data_path}/{f}\")\n",
    "            continue\n",
    "        \n",
    "        #print(img) #will get img as an array\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the image to a numpy type\n",
    "\n",
    "images = np.array(images)\n",
    "images.shape \n",
    "#prints out (total number of imgs, the length size, the width size, the number of channels (rgb thus 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "y = scenes_dataframe['scene type'].values\n",
    "#print(y[:5])\n",
    "\n",
    "#for y \n",
    "y_labelencoder = LabelEncoder ()\n",
    "y_encoded = y_labelencoder.fit_transform (y)\n",
    "print(y)\n",
    "#print(y_encoded)\n",
    "\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "ct = ColumnTransformer([('OneHotEncoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "\n",
    "Y = ct.fit_transform(y)\n",
    "Y.shape\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state = 1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size = 0.05, random_state = 415)\n",
    "\n",
    "#impact the shape of the training and testing\n",
    "print(train_x.shape) #(number of images)\n",
    "print(train_y.shape)\n",
    "\n",
    "\n",
    "print(test_x.shape) #(number to test)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pydot \n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is input, y=F(x)\n",
    "# identity block simply means input should be equal to output. \n",
    "#  y = x + F(x)   the layers in a traditional network are learning the true output H(x)\n",
    "# F(x) = y - x   the layers in a residual network are learning the residual F(x)\n",
    "# Hence, the name: Residual Block.\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "   \n",
    "    Arguments:\n",
    "    X -- input of shape (m, height, width, channel)\n",
    "    f -- shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Saving the input value.we need this later to add to the output. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    # First layer \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X) # 1,1 is filter size\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)  # normalization on channels\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "      \n",
    "    # Second layer  (f,f)=3*3 filter by default\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Third layer\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value here, and pass it through a RELU activation \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each ResNet block is either 2 layer deep\n",
    "def ResNet50(input_shape=(64, 64, 3), classes=3):\n",
    "    \"\"\"\n",
    "    Implementation of the ResNet50 architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input) #3,3 padding\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X) #64 filters of 7*7 \n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X) #batchnorm applied on channels\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X) #window size is 3*3\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    # convolutional_block is a function defined above. Convolutional_block have 3 layers.\n",
    "    #filters=[64, 64, 256] first 64 is for 1st layer and 2nd 64 is for 2nd layer and 256 is for 3rd layer of convultional block   \n",
    "    # below are the conv layers from convolutional_block function\n",
    "    #X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
    "    #X = Conv2D(F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    #X = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
    "   \n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b') \n",
    "    #X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
    "    #X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    #X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "  \n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    #X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
    "    #X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    #X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 \n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 \n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 \n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL \n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (224, 224, 3), classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr_rate = 0.1\n",
    "lr_schedule = ExponentialDecay(init_lr_rate, decay_steps = 100000, decay_rate = 0.9, staircase = True)\n",
    "optimizer = Adam(learning_rate = lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#binary_crossentropy measures the difference between true labels and predicted prob for classification problems\n",
    "#categorical_crossentropy when you have a multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', min_delta =.05, patience = 5, verbose = 1, mode = 'auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(train_x, train_y, epochs = epochs, batch_size = batch_size, validation_data = (test_x, test_y), callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(test_x, test_y)\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_resnet50live_run.keras')\n",
    "\n",
    "best_acc = max(training_history.history['val_accuracy'])\n",
    "print(f'best accuracy: {best_acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "fig.suptitle('Learning Curves')\n",
    "\n",
    "ax[0].plot(training_history.history['loss'], color ='b', label =\"Training loss\")\n",
    "ax[0].plot(training_history.history['val_loss'], color ='r', label = \"validation loss\")\n",
    "legend = ax[0].legend(loc ='best', shadow = True)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "\n",
    "ax[1].plot(training_history.history['accuracy'], color ='b', label =\"Training accuracy\")\n",
    "ax[1].plot(training_history.history['val_accuracy'], color ='r', label =\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc ='best', shadow = True)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title ='Confusion Matrix', cmap = plt.cm.Blues):\n",
    "  \"\"\"\n",
    "  This function prints and plots the confusion matrix.\n",
    "  Normalization can be applied by setting normalize = True.\n",
    "  \"\"\"\n",
    "  plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "  #cm is an array rep the img to be displayed\n",
    "  #interpolation:use nearest method for calculating pixel values when resizing\n",
    "  #cmap: parameter used to specify color scale to be used for mapping scalar data to colors\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  #configure tick marks based on length of classes array\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation = 45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "  thresh = cm.max() / 2.\n",
    "\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(test_x)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1)\n",
    "Y_true = np.argmax(test_y, axis = 1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "def camera_frame(frame):\n",
    "    frame = cv2.resize(frame, (224,224)) #resize the current frame to 224,224\n",
    "    x = image.img_to_array(frame)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x) \n",
    "    return x\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 32:\n",
    "\n",
    "        x = camera_frame(frame)\n",
    "        prediction = model.predict(x)\n",
    "        print(\"Prediction: \", prediction)\n",
    "\n",
    "        imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    if key == ord('q'): #press q to quit\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
